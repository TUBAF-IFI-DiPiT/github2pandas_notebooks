{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Workflow Data Aggregation\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "This example illustrates the aggregation of workflow (actions) data using the `github2pandas` repository. Here, all workflows are read out, filtered and displayed in terms of success or failure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github2pandas.workflows import Workflows\n",
    "from github2pandas.utility import Utility\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "The most important input parameter is an Repository object from PyGitHub-Package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_repo_name = \"github2pandas\"\n",
    "git_repo_owner = \"TUBAF-IFI-DiPiT\"\n",
    "    \n",
    "default_data_folder = Path(\"data\", git_repo_name)\n",
    "\n",
    "github_token = os.environ['GITHUB_API_TOKEN']\n",
    "# If you do not include your Github Token in .env, its neccessary to integrate it here. \n",
    "# github_token = \"yourToken\"\n",
    "\n",
    "repo = Utility.get_repo(git_repo_owner, git_repo_name, github_token, default_data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snipet generates a raw data set based on repo information. The pandas Dataframe includes authorÂ´s information, timestamp and the general result of the workflow run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Workflows.generate_workflow_pandas_tables(repo=repo, data_root_dir=default_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_workflow = Workflows.get_workflows(data_root_dir=default_data_folder)\n",
    "pd_workflow.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_run = Workflows.get_workflows(data_root_dir=default_data_folder, filename = Workflows.WORKFLOWS_RUNS)\n",
    "pd_run.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get workflow run logs\n",
    "What happens during the workflow run. Let's take a closer view on log files of a specific Action run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Workflows.download_workflow_log_files(repo=repo,\n",
    "                                  github_token=github_token,\n",
    "                                  workflow_run_id=1322994624,\n",
    "                                  data_root_dir=default_data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow logs are stored in the data folder of the project now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check who prepared the workflows\n",
    "\n",
    "For this request we have to merge Version data with Workflow information. \n",
    "\n",
    "1. Prepare commit, edits and workflow dataframes\n",
    "2. Extract commits adressing workflow-folder `.github/workflow/` from edits\n",
    "3. Identify authors integrating workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github2pandas.version import Version\n",
    "Version.clone_repository(repo=repo, data_root_dir=default_data_folder, github_token=github_token)\n",
    "Version.no_of_proceses = 8\n",
    "Version.generate_version_pandas_tables(repo=repo, data_root_dir=default_data_folder)\n",
    "\n",
    "pd_edits = Version.get_version(data_root_dir=default_data_folder, filename=Version.VERSION_EDITS)\n",
    "pd_commits = Version.get_version(data_root_dir=default_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_commits = pd_edits[pd_edits[\"new_path\"].str.contains(\".github/workflows/\", na=False)][['commit_sha', 'filename']]\n",
    "relevant_commits.drop_duplicates(inplace = True)\n",
    "relevant_commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(relevant_commits, pd_commits[['author', 'commit_sha', 'commited_at']],\n",
    "         how=\"left\", left_on = \"commit_sha\", right_on = \"commit_sha\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
